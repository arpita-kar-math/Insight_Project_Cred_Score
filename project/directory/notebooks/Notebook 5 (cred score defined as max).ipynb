{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunk = pd.read_csv('df_mean_cred_score.csv', usecols=['full_name', 'slug', 'job_title', 'brand_name', 'is_c_level',  'is_current', 'growth_score',\n",
    "                                                          'sudden_growth_score', 'sudden_growth_delta', 'acceleration_score', 'success_score', \n",
    "                                                          'is_physical_products_brand', 'is_brickandmortar','generic_reseller', \n",
    "                                                          'store_is_subdomain','cred_score_weighted_mean_mean','cred_score_weighted_mean_max', \n",
    "                                                          'num_brand_count','position_weight', 'experience_w_brand_ratio', 'cred_score_weighted_median'], chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 368 ms, total: 21.9 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#This is in case you use chunks in pandas to upload your file.\n",
    "chunk_list = []  # append each chunk df here \n",
    "\n",
    "# Each chunk is in df format\n",
    "for chunk in df_chunk:\n",
    "    # Once the data filtering is done, append the chunk to list\n",
    "    chunk_list.append(chunk)\n",
    "    \n",
    "# concat the list into dataframe \n",
    "df = pd.concat(chunk_list)\n",
    "del chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The loyalty column\n",
    "df.loc[(df['num_brand_count'] >=2),'num_brand_association'] = 0\n",
    "df.loc[(df['num_brand_count'] <2),'num_brand_association'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 1.21 s, total: 2.57 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#here I am not using experience with brand ratio, that seems like a internal factor to just calculate score\n",
    "X = df[['is_current','is_c_level', 'is_physical_products_brand', 'is_brickandmortar', 'generic_reseller',\n",
    "       'store_is_subdomain', 'num_brand_association', 'cred_score_weighted_median']]\n",
    "y = df['growth_score']\n",
    "#Let me use stats model first to run a Linear regression on my dataset and look at the r^2 value\n",
    "import statsmodels.api as sm\n",
    "X_withconstant = sm.add_constant(X)\n",
    "# 1. Instantiate model\n",
    "lm_cs_1 = sm.OLS(y.astype(float),X_withconstant.astype(float))\n",
    "\n",
    "# 2. Fit model\n",
    "lm_cs_1 = lm_cs_1.fit()\n",
    "\n",
    "lm_cs_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>growth_score</td>   <th>  R-squared:         </th>  <td>   0.225</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.225</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.497e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 09 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:50:39</td>     <th>  Log-Likelihood:    </th> <td>-6.9154e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1511854</td>     <th>  AIC:               </th>  <td>1.383e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1511845</td>     <th>  BIC:               </th>  <td>1.383e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                      <td>   28.6825</td> <td>    0.083</td> <td>  347.324</td> <td> 0.000</td> <td>   28.521</td> <td>   28.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_current</th>                 <td>   -8.1794</td> <td>    0.060</td> <td> -135.701</td> <td> 0.000</td> <td>   -8.298</td> <td>   -8.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_c_level</th>                 <td>   -7.7381</td> <td>    0.050</td> <td> -153.466</td> <td> 0.000</td> <td>   -7.837</td> <td>   -7.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_physical_products_brand</th> <td>    8.3676</td> <td>    0.043</td> <td>  195.876</td> <td> 0.000</td> <td>    8.284</td> <td>    8.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_brickandmortar</th>          <td>    0.8500</td> <td>    0.039</td> <td>   21.754</td> <td> 0.000</td> <td>    0.773</td> <td>    0.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generic_reseller</th>           <td>   -8.2630</td> <td>    0.331</td> <td>  -24.944</td> <td> 0.000</td> <td>   -8.912</td> <td>   -7.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>store_is_subdomain</th>         <td>  -12.5872</td> <td>    0.075</td> <td> -166.803</td> <td> 0.000</td> <td>  -12.735</td> <td>  -12.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_brand_association</th>      <td>  -11.5548</td> <td>    0.067</td> <td> -172.418</td> <td> 0.000</td> <td>  -11.686</td> <td>  -11.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cred_score_weighted_median</th> <td>    0.2010</td> <td>    0.000</td> <td>  531.272</td> <td> 0.000</td> <td>    0.200</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>121783.580</td> <th>  Durbin-Watson:     </th>  <td>   0.547</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>156300.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 0.726</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 3.611</td>   <th>  Cond. No.          </th>  <td>    925.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           growth_score   R-squared:                       0.225\n",
       "Model:                            OLS   Adj. R-squared:                  0.225\n",
       "Method:                 Least Squares   F-statistic:                 5.497e+04\n",
       "Date:                Tue, 09 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        20:50:39   Log-Likelihood:            -6.9154e+06\n",
       "No. Observations:             1511854   AIC:                         1.383e+07\n",
       "Df Residuals:                 1511845   BIC:                         1.383e+07\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "const                         28.6825      0.083    347.324      0.000      28.521      28.844\n",
       "is_current                    -8.1794      0.060   -135.701      0.000      -8.298      -8.061\n",
       "is_c_level                    -7.7381      0.050   -153.466      0.000      -7.837      -7.639\n",
       "is_physical_products_brand     8.3676      0.043    195.876      0.000       8.284       8.451\n",
       "is_brickandmortar              0.8500      0.039     21.754      0.000       0.773       0.927\n",
       "generic_reseller              -8.2630      0.331    -24.944      0.000      -8.912      -7.614\n",
       "store_is_subdomain           -12.5872      0.075   -166.803      0.000     -12.735     -12.439\n",
       "num_brand_association        -11.5548      0.067   -172.418      0.000     -11.686     -11.423\n",
       "cred_score_weighted_median     0.2010      0.000    531.272      0.000       0.200       0.202\n",
       "==============================================================================\n",
       "Omnibus:                   121783.580   Durbin-Watson:                   0.547\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           156300.828\n",
       "Skew:                           0.726   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.611   Cond. No.                         925.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_cs_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 s, sys: 163 ms, total: 1.9 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from tempfile import mkdtemp\n",
    "#cachedir = mkdtemp()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 407 ms, total: 1min 15s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "ran_reg_2 = RandomForestRegressor(max_features = 4, max_depth =100)\n",
    "ran_reg_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.267776372975405"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2 = ran_reg_2.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4209100222766128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_scores(model):\n",
    "    scores = cross_val_score(model,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv=5,\n",
    "                             scoring='r2')\n",
    "    \n",
    "    print('CV Mean: ', np.mean(scores))\n",
    "    print('STD: ', np.std(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic_reseller               0.024729\n",
      "is_brickandmortar              0.242635\n",
      "num_brand_association          0.935436\n",
      "is_c_level                     1.285323\n",
      "is_current                     1.580444\n",
      "is_physical_products_brand     2.655380\n",
      "store_is_subdomain             2.993113\n",
      "cred_score_weighted_median    90.282942\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_importance_rf = ran_reg_2.feature_importances_*100\n",
    "rel_imp = pd.Series(feature_importance_rf, index = X.columns).sort_values(inplace = False)\n",
    "print(rel_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=10,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             n_iter_no_change=None, presort='auto', random_state=1,\n",
       "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us try fitting a gradient boost regressor to our data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regrboost_1 = GradientBoostingRegressor(n_estimators = 100, learning_rate = .01, random_state =1, max_depth =10)\n",
    "regrboost_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.04707974890293"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2_boost = regrboost_1.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, pred_2_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488564769420484"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, pred_2_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['is_current','is_c_level', 'is_physical_products_brand', 'is_brickandmortar', 'generic_reseller',\n",
    "       'store_is_subdomain', 'num_brand_association', 'cred_score_weighted_median']]\n",
    "y = df['growth_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1058297, 8), (453557, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape\n",
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an artificial neural network model for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-64a11ad2c1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
